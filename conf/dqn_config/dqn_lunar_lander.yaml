seed: 0
num_iters: 125000
num_envs: 8
env_name: LunarLander-v2

# replay buffer config;
buffer_capacity: 1000000
batch_size: 128
# collect that many from uniform policy, before
# training starts;
uniform_experience: 50000

# annealer config;
annealer: null
max_eps: 1
min_eps: 0.1
anneal_steps: 50000

# Qfunc config;
update_target_every_n_grad_steps: 1000
mlp_config:
    n_hidden: 2
    hidden_dim: 64
discount: 0.99
lr: 3e-4
max_grad_norm: 1
ortho_init: true
do_abs_loss: false