seed: 0
num_iters: 62500
num_envs: 8
env_name: LunarLander-v2
log_training_every_n_grad_step: 25
grad_step_freq: 1

# replay buffer config;
buffer_capacity: 10000
batch_size: 128
# collect that many from uniform policy, before
# training starts;
uniform_experience: 10000

# annealer config;
annealer: cos
max_eps: 1
min_eps: 0.1
# recommended is num_iters / grad_step_freq / 2
# since annealing done every grad step
anneal_steps: 30000

# Qfunc config;
update_target_every_n_grad_steps: 500
mlp_config:
    n_hidden: 2
    hidden_dim: 64
discount: 0.99
lr: 3e-4
max_grad_norm: 1
ortho_init: true
do_abs_loss: false